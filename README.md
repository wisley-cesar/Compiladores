# Compilador - Analisador LÃ©xico

Este projeto implementa um analisador lÃ©xico (lexer) para uma linguagem de programaÃ§Ã£o simples, desenvolvido em Dart como parte de um projeto acadÃªmico de compiladores.

## ğŸ“‹ VisÃ£o Geral

O analisador lÃ©xico Ã© a primeira fase de um compilador, responsÃ¡vel por converter o cÃ³digo-fonte em uma sequÃªncia de tokens. Este projeto implementa um **AutÃ´mato Finito DeterminÃ­stico (AFD)** para reconhecimento eficiente de tokens.

## ğŸ¯ Funcionalidades

### âœ… Tokens Reconhecidos

- **Palavras Reservadas**: `if`, `else`, `while`, `for`, `int`, `float`, `string`, `bool`, `return`, `void`, etc.
- **Identificadores**: Nomes de variÃ¡veis, funÃ§Ãµes (ex: `variavel`, `_variavel`, `var123`)
- **Literais NumÃ©ricos**: Inteiros (`123`), decimais (`3.14`), notaÃ§Ã£o cientÃ­fica (`1.23e5`)
- **Strings Literais**: Entre aspas duplas com escape sequences (`"Hello\\n"`)
- **Literais Booleanos**: `true`, `false`
- **Operadores**: `+`, `-`, `*`, `/`, `=`, `==`, `!=`, `<`, `>`, `<=`, `>=`, `&&`, `||`, etc.
- **SÃ­mbolos Especiais**: `(`, `)`, `{`, `}`, `[`, `]`, `;`, `,`, `.`, `:`

### âœ… Tratamento de ComentÃ¡rios

- **ComentÃ¡rios de linha**: `// comentÃ¡rio`
- **ComentÃ¡rios de bloco**: `/* comentÃ¡rio */`

### âœ… Tratamento de Erros LÃ©xicos

- DetecÃ§Ã£o de strings nÃ£o fechadas
- Caracteres invÃ¡lidos
- NÃºmeros malformados
- RelatÃ³rio detalhado de erros com posiÃ§Ã£o (linha/coluna)

### âœ… Recursos AvanÃ§ados

- **Rastreamento de posiÃ§Ã£o**: Linha e coluna para cada token
- **EstatÃ­sticas**: Contadores por tipo de token
- **RelatÃ³rios detalhados**: AnÃ¡lise completa do cÃ³digo
- **Testes abrangentes**: Cobertura completa de funcionalidades

## ğŸ—ï¸ Arquitetura

### Estrutura do Projeto

```
compilador/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ lexer.dart              # Analisador lÃ©xico principal
â”‚   â”œâ”€â”€ token.dart              # DefiniÃ§Ãµes de tokens
â”‚   â”œâ”€â”€ error_handler.dart      # Tratamento de erros lÃ©xicos
â”‚   â”œâ”€â”€ token_recognizer.dart   # Reconhecedores de tokens especÃ­ficos
â”‚   â”œâ”€â”€ ambiguity_detector.dart # DetecÃ§Ã£o de ambiguidades sintÃ¡ticas
â”‚   â””â”€â”€ statistics.dart         # EstatÃ­sticas e relatÃ³rios
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ main.dart               # Programa principal
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ compilador_test.dart
â”‚   â””â”€â”€ ambiguidade_test.dart
â”œâ”€â”€ pubspec.yaml
â””â”€â”€ README.md                   # Esta documentaÃ§Ã£o
```

### Arquitetura Modular

O projeto foi refatorado para seguir o princÃ­pio de **SeparaÃ§Ã£o de Responsabilidades**, dividindo o lexer em mÃ³dulos especializados:

#### ğŸ”§ **MÃ³dulos Principais**

1. **`Lexer`** - Orquestrador principal
   - Coordena todos os mÃ³dulos
   - Implementa o AFD (AutÃ´mato Finito DeterminÃ­stico)
   - Gerencia o fluxo de anÃ¡lise

2. **`TokenRecognizer`** - Reconhecimento de tokens
   - Strings literais com escape sequences
   - NÃºmeros (inteiros, decimais, notaÃ§Ã£o cientÃ­fica)
   - Identificadores e palavras reservadas
   - Operadores e sÃ­mbolos
   - ComentÃ¡rios (linha e bloco)

3. **`ErrorHandler`** - Tratamento de erros
   - Coleta e organiza erros lÃ©xicos
   - Fornece estatÃ­sticas de erros
   - MantÃ©m lista de erros para relatÃ³rios

4. **`Statistics`** - EstatÃ­sticas e relatÃ³rios
   - Contadores de tokens por tipo
   - Percentuais de distribuiÃ§Ã£o
   - RelatÃ³rios detalhados
   - MÃ©tricas de anÃ¡lise

### Classes Principais

#### `TokenType` (Enum)
Define todos os tipos de tokens reconhecidos:
- `palavraReservada`, `identificador`, `numero`, `string`, `booleano`
- `operador`, `simbolo`, `comentario`, `erro`, `eof`

#### `Token` (Classe)
Representa um token com:
- Tipo do token
- Lexema (texto reconhecido)
- PosiÃ§Ã£o (linha e coluna)
- MÃ©todos auxiliares para classificaÃ§Ã£o

#### `Lexer` (Classe Principal)
Implementa o analisador lÃ©xico com:
- **AFD**: AutÃ´mato finito determinÃ­stico para reconhecimento
- **Tratamento de erros**: DetecÃ§Ã£o e relatÃ³rio de erros lÃ©xicos
- **EstatÃ­sticas**: Contadores e mÃ©tricas de anÃ¡lise
- **RelatÃ³rios**: SaÃ­da formatada dos resultados

## ğŸš€ Como Usar

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Executar o programa principal
dart run bin/main.dart

# Executar testes (formato expandido para saÃ­da detalhada)
dart test -r expanded

# AnÃ¡lise estÃ¡tica
dart analyze
```

### Exportar tokens para arquivo

O CLI agora permite exportar os tokens reconhecidos para um arquivo JSON usando a flag `--tokens-out <file>`.

Exemplo:

```bash
# Analisar um arquivo e mostrar tokens em JSON na saÃ­da
dart run bin/main.dart examples/demo.src --dump-tokens-json

# Analisar e gravar tokens no arquivo `out/tokens.json`
dart run bin/main.dart examples/demo.src --tokens-out out/tokens.json
```

Se `--tokens-out` for usada, o programa criarÃ¡ o arquivo (com diretÃ³rios necessÃ¡rios) e gravarÃ¡ o JSON formatado dos tokens.


### Exemplo de Uso

```dart
import 'package:compilador/lexica/lexer.dart';

void main() {
  final codigo = '''
    int x = 10;
    float y = 3.14;
    String nome = "JoÃ£o";
    bool ativo = true;
    
    if (x > 5 && y < 10.0) {
        x = x + 1;
    }
  ''';

  final lexer = Lexer(codigo);
  final tokens = lexer.analisar();
  
  // Imprimir relatÃ³rio detalhado
  lexer.imprimirRelatorio();
  
  // Verificar erros
  if (lexer.temErros) {
    for (final erro in lexer.listaErros) {
      print('âŒ $erro');
    }
  }
}
```

### Exemplo mÃ­nimo â€” usar o Lexer com uma string (linha de comando)

```dart
import 'package:compilador/lexica/lexer.dart';

void main() {
  final codigo = 'uids x = (1 + 2) * 3;';
  final lexer = Lexer(codigo);
  final tokens = lexer.analisar();

  for (final t in tokens) {
    print(t.toString());
  }
}
```

SaÃ­da exemplo (lista de tokens):

```
(palavraReservada, "uids", linha: 1, col: 1)
(identificador, "x", linha: 1, col: 6)
(operador, "=", linha: 1, col: 8)
(simbolo, "(", linha: 1, col: 10)
(numero, "1", linha: 1, col: 11)
(operador, "+", linha: 1, col: 13)
(numero, "2", linha: 1, col: 15)
(simbolo, ")", linha: 1, col: 16)
(operador, "*", linha: 1, col: 18)
(numero, "3", linha: 1, col: 20)
(simbolo, ";", linha: 1, col: 21)
(eof, "EOF", linha: 1, col: 22)
```

### Exemplo: ler de um arquivo e imprimir tokens + symbol table (JSON)

```dart
import 'dart:io';
import 'dart:convert';
import 'package:compilador/lexica/lexer.dart';
import 'package:compilador/symbol_table.dart';

void main() {
  final path = 'examples/demo.src';
  final src = File(path).readAsStringSync();

  final lexer = Lexer(src);
  final tokens = lexer.analisar();

  for (final t in tokens) print(t);

  // Supondo que o fluxo de parsing/semÃ¢ntica jÃ¡ tenha sido executado
  // e que vocÃª tenha uma SymbolTable (aqui mostramos um exemplo simples):
  final table = SymbolTable();
  table.add('x', type: 'int');
  table.add('s', type: 'string');

  final jsonSymbols = jsonEncode(table.allSymbols.map((s) => s.toJson()).toList());
  print('\nSymbol Table (JSON):');
  print(jsonSymbols);
}
```

Exemplo de saÃ­da (JSON):

```json
[{"id":1,"name":"x","type":"int","isMutable":true},
 {"id":2,"name":"s","type":"string","isMutable":true}]
```

## Erros lÃ©xicos estruturados

O lexer tambÃ©m expÃµe erros lÃ©xicos em formato estruturado atravÃ©s do getter `lexer.listaErrosEstruturados`, que retorna uma `List<LexError>` com os campos:

- `mensagem` (String): descriÃ§Ã£o curta do erro.
- `linha` (int): linha onde o erro ocorreu (1-based).
- `coluna` (int): coluna onde o erro ocorreu (1-based).
- `contexto` (String): trecho do cÃ³digo ao redor da posiÃ§Ã£o do erro (com novas linhas substituÃ­das por `\u21B5` para legibilidade).

Exemplo de uso:

```dart
final lexer = Lexer('int x = @ 42;');
final tokens = lexer.analisar();
if (lexer.temErros) {
  for (final err in lexer.listaErrosEstruturados) {
    print('Erro: ${err.mensagem} (linha: ${err.linha}, coluna: ${err.coluna})');
    print('Contexto: ' + err.contexto);
  }
}
```

Essa representaÃ§Ã£o facilita relatÃ³rios, testes e integraÃ§Ã£o com ferramentas que consumam erros estruturados (por exemplo, formatadores de IDE).


## ğŸ“Š Exemplo de SaÃ­da

```
=== RELATÃ“RIO DE ANÃLISE LÃ‰XICA ===
Total de tokens: 25
Total de erros: 0
Linhas processadas: 6

TOKENS RECONHECIDOS:
  Palavra reservada: int
  Identificador: x
  Operador: =
  NÃºmero: 10
  SÃ­mbolo: ;
  Palavra reservada: float
  Identificador: y
  Operador: =
  NÃºmero: 3.14
  SÃ­mbolo: ;
  ...

=== ESTATÃSTICAS ===
Total de tokens: 25
Total de erros: 0
Linhas processadas: 6

Contadores por tipo:
  TokenType.palavraReservada: 4
  TokenType.identificador: 6
  TokenType.operador: 8
  TokenType.numero: 3
  TokenType.simbolo: 4
```

## ğŸ§ª Testes

O projeto inclui testes abrangentes que cobrem:

- **Reconhecimento de tokens**: Todos os tipos de tokens
- **ComentÃ¡rios**: Linha e bloco
- **Tratamento de erros**: Strings nÃ£o fechadas, caracteres invÃ¡lidos
- **PosiÃ§Ã£o dos tokens**: Rastreamento correto de linha/coluna
- **EstatÃ­sticas**: ValidaÃ§Ã£o de mÃ©tricas

Execute os testes com:
```bash
dart test
```

## ğŸ”§ ImplementaÃ§Ã£o TÃ©cnica

### AutÃ´mato Finito DeterminÃ­stico (AFD)

O lexer implementa um AFD para reconhecimento eficiente de tokens:

1. **Estados**: Caracteres, dÃ­gitos, letras, sÃ­mbolos
2. **TransiÃ§Ãµes**: Baseadas no caractere atual
3. **Estados finais**: Tokens reconhecidos
4. **Tratamento de erros**: Estados de erro

### Algoritmo Principal

```dart
while (pos < codigo.length) {
  final char = codigo[pos];
  
  if (char == ' ' || char == '\t') {
    avancar(); // Ignorar espaÃ§os
  } else if (char == '\n') {
    linha++; coluna = 1; // Nova linha
  } else if (char == '/' && proximo == '/') {
    ignorarComentarioLinha();
  } else if (char == '"') {
    lerString();
  } else if (_isDigit(char)) {
    lerNumero();
  } else if (_isLetter(char)) {
    lerIdentificadorOuPalavraReservada();
  } else if (_isOperadorOuSimbolo(char)) {
    lerOperadorOuSimbolo();
  } else {
    adicionarErro('Caractere invÃ¡lido');
  }
}
```

## ğŸ“ˆ CritÃ©rios de AvaliaÃ§Ã£o

### âœ… Corretude (40%)
- âœ… Reconhece todos os tipos de tokens corretamente
- âœ… Trata comentÃ¡rios adequadamente
- âœ… Detecta e reporta erros lÃ©xicos
- âœ… MantÃ©m posiÃ§Ã£o correta dos tokens

### âœ… AbrangÃªncia (20%)
- âœ… Palavras reservadas completas
- âœ… Operadores unÃ¡rios e binÃ¡rios
- âœ… NÃºmeros inteiros, decimais e cientÃ­ficos
- âœ… Strings com escape sequences
- âœ… SÃ­mbolos especiais

### âœ… Tratamento de Erros (15%)
- âœ… Strings nÃ£o fechadas
- âœ… Caracteres invÃ¡lidos
- âœ… NÃºmeros malformados
- âœ… RelatÃ³rio detalhado com posiÃ§Ã£o

### âœ… Clareza do CÃ³digo (10%)
- âœ… CÃ³digo bem documentado
- âœ… Estrutura modular
- âœ… Nomes descritivos
- âœ… SeparaÃ§Ã£o de responsabilidades

### âœ… DocumentaÃ§Ã£o (15%)
- âœ… README completo
- âœ… ComentÃ¡rios no cÃ³digo
- âœ… Exemplos de uso
- âœ… ExplicaÃ§Ã£o da implementaÃ§Ã£o

## ğŸ“ Aspectos Conceituais

### DescriÃ§Ã£o dos Tokens

O analisador reconhece as seguintes classes de tokens:

1. **Palavras Reservadas**: Elementos da linguagem com significado especial
2. **Identificadores**: Nomes definidos pelo programador
3. **Literais**: Valores constantes (nÃºmeros, strings, booleanos)
4. **Operadores**: SÃ­mbolos para operaÃ§Ãµes
5. **SÃ­mbolos**: Delimitadores e pontuaÃ§Ã£o

### Abordagem de ImplementaÃ§Ã£o

- **AFD**: AutÃ´mato finito determinÃ­stico para reconhecimento eficiente
- **Lookahead**: AnÃ¡lise de caracteres Ã  frente para operadores multi-caractere
- **Estado**: Rastreamento de posiÃ§Ã£o e contexto
- **RecuperaÃ§Ã£o de erros**: ContinuaÃ§Ã£o da anÃ¡lise apÃ³s erros

### Exemplos de Entrada e SaÃ­da

**Entrada:**
```c
int x = 10;
float y = 3.14;
String nome = "JoÃ£o";
bool ativo = true;

if (x > 5 && y < 10.0) {
    x = x + 1;
}
```

**SaÃ­da:**
```
(PALAVRARESERVADA, "int", linha: 1, col: 4)
(IDENTIFICADOR, "x", linha: 1, col: 6)
(OPERADOR, "=", linha: 1, col: 7)
(NUMERO, "10", linha: 1, col: 11)
(SIMBOLO, ";", linha: 1, col: 11)
...
```

### DiscussÃ£o sobre Erros LÃ©xicos

O analisador trata os seguintes tipos de erros:

1. **Strings nÃ£o fechadas**: Detecta quando uma string nÃ£o Ã© fechada adequadamente
2. **Caracteres invÃ¡lidos**: Identifica sÃ­mbolos nÃ£o reconhecidos
3. **NÃºmeros malformados**: Detecta formatos numÃ©ricos invÃ¡lidos
4. **SequÃªncias de escape invÃ¡lidas**: Valida escape sequences em strings

## ğŸš€ PrÃ³ximos Passos

Para completar o compilador, os prÃ³ximos passos seriam:

1. **Analisador SintÃ¡tico (Parser)**: AnÃ¡lise da estrutura gramatical
2. **Analisador SemÃ¢ntico**: VerificaÃ§Ã£o de tipos e contexto
3. **Gerador de CÃ³digo**: ProduÃ§Ã£o de cÃ³digo intermediÃ¡rio ou final
4. **OtimizaÃ§Ãµes**: Melhorias de performance

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido como parte de um trabalho acadÃªmico de compiladores.

---

**Desenvolvido com â¤ï¸ em Dart para fins educacionais**

## ğŸ§­ DescriÃ§Ã£o do AutÃ´mato LÃ©xico (AFD)

O lexer implementa uma mÃ¡quina de estados (AFD-like) para reconhecer tokens. Abaixo estÃ¡ uma visÃ£o simplificada dos estados principais e transiÃ§Ãµes.

Estados principais:

- start: estado inicial; decide o prÃ³ximo estado com base no caractere atual
- inNumber: reconhecendo dÃ­gitos e ponto decimal; tambÃ©m lida com expoentes (e/E)
- inIdentifier: reconhecendo letras, dÃ­gitos e underscore para identificadores e palavras reservadas
- inString: dentro de uma string entre aspas; processa escapes e detecta fim de string
- inCommentLine: ignorando atÃ© o fim da linha
- inCommentBlock: ignorando atÃ© encontrar */ ou EOF (erro se EOF antes de fechar)
- operatorLookahead: tenta reconhecer operadores de 3/2/1 caracteres (prioriza maior)

Diagrama simplificado (ASCII):

```
            +-------+
            | start |
            +---+---+
                |
    digits -> inNumber <- '.'? <- digits
      |         |\
      |         | \__ 'e'/'E' -> exponent handling
      |         v
    letters -> inIdentifier
      |                 \
      v                  '--> reserved/identifier (emit token)
    '"' -> inString -> (escape sequences) -> '"' emit string
    '/' -> (next=='/') inCommentLine -> consume until '\n'
           (next=='*') inCommentBlock -> consume until '*/' or error
    operator chars -> operatorLookahead -> emit operator token
```

Notas:

- O estado operatorLookahead tenta reconhecer primeiro seqÃ¼Ãªncias de 3 caracteres, depois 2 e por fim 1.
- Strings e comentÃ¡rios atualizam contadores de linha/coluna para manter posiÃ§Ãµes corretas.
- NÃºmeros validam formato (ponto decimal e expoente); expoente invÃ¡lido gera erro lÃ©xico e consumo seguro para recuperaÃ§Ã£o.

Esta seÃ§Ã£o pode ser expandida com um diagrama PlantUML ou um AFD formal para documentaÃ§Ã£o acadÃªmica.